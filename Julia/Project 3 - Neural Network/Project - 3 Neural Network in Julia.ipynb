{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - 3: Neural Network in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huy Huynh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA4319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a computational learning system that uses a network of functions to understand and translate a data input of one form into a desired output, usually in another form. The concept of the artificial neural network was inspired by human biology and the way neurons of the human brain function together to understand inputs from human senses. \n",
    "\n",
    "Neural networks are just one of many tools and approaches used in machine learning algorithms. The neural network itself may be used as a piece in many different machine learning algorithms to process complex data inputs into a space that computers can understand. \n",
    "\n",
    "Neural networks are being applied to many real-life problems today, including speech and image recognition, spam email filtering, finance, and medical diagnosis, to name a few. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](https://www.researchgate.net/profile/Facundo-Bre/publication/321259051/figure/fig1/AS:614329250496529@1523478915726/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning algorithms that use neural networks generally do not need to be programmed with specific rules that define what to expect from the input. The neural net learning algorithm instead learns from processing many labeled examples (i.e. data with with \"answers\") that are supplied during training and using this answer key to learn what characteristics of the input are needed to construct the correct output. Once a sufficient number of examples have been processed, the neural network can begin to process new, unseen inputs and successfully return accurate results. The more examples and variety of inputs the program sees, the more accurate the results typically become because the program learns with experience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Neural Networks today\n",
    "\n",
    "Neural networks can be applied to a broad range of problems and can assess many different types of input, including images, videos, files, databases, and more. They also do not require explicit programming to interpret the content of those inputs.\n",
    "\n",
    "Because of the generalized approach to problem solving that neural networks offer, there is virtually no limit to the areas that this technique can be applied. Some common applications of neural networks today, include image/pattern recognition, self driving vehicle trajectory prediction, facial recognition, data mining, email spam filtering, medical diagnosis, and cancer research. There are many more ways that neural nets are used today, and adoption is increasing rapidly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "#Load Packages\n",
    "using Pkg\n",
    "Pkg.add(\"MLDatasets\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"TestImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using Images\n",
    "using TestImages\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency MNIST.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: THE MNIST DATABASE of handwritten digits\n",
      "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
      "Website: http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "[LeCun et al., 1998a]\n",
      "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
      "    \"Gradient-based learning applied to document recognition.\"\n",
      "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
      "\n",
      "The files are available for download at the offical\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of MNIST aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"/Users/huyhuynh/.julia/datadeps/MNIST\"?\n",
      "[y/n]\n",
      "stdin> MNIST\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"/Users/huyhuynh/.julia/datadeps/MNIST\"?\n",
      "[y/n]\n",
      "stdin> y\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,test_y = MNIST.testdata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{N0f8,2} with eltype N0f8:\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0    …  0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0    …  0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0    …  0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.125  0.043     0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.569  0.929  0.686     0.0    0.0    0.0  0.0  0.0  0.0\n",
       " ⋮                          ⋮             ⋱                     ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.988  0.988  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.992  0.992  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.137  0.137  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0    …  0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0    …  0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0    0.0    0.0       0.0    0.0    0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
      " \u001b[90m [82e4d734] \u001b[39m\u001b[92m+ ImageIO v0.5.3\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m QuartzImageIO ─ v0.7.3\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
      " \u001b[90m [dca85d43] \u001b[39m\u001b[92m+ QuartzImageIO v0.7.3\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Manifest.toml`\n",
      " \u001b[90m [dca85d43] \u001b[39m\u001b[92m+ QuartzImageIO v0.7.3\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mQuartzImageIO\n",
      "1 dependency successfully precompiled in 4 seconds (278 already precompiled)\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
      " \u001b[90m [6218d12a] \u001b[39m\u001b[92m+ ImageMagick v1.2.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"ImageIO\")\n",
    "Pkg.add(\"QuartzImageIO\")\n",
    "Pkg.add(\"ImageMagick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First  image in train dataset is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAVxJREFUaAW9wS3OXAUAhtGT5lEoVkAIGEpCUFhWUBBoNCh+lvAlrIC0okF1LawBSg1iDAaDwU4RIyqZe5u852QsYxnLWMYylrGMZSxjGctYxjKWsYzloJ/xPX7DE1wck7GMZSwHvI+vccVjfISLYzKWsYzlgL/xK750XsYylrEc8C8u3k7GMpaxHPAuPvV2MpaxjOWAd/CeNz7DK1zcL2MZy1gO+Asv8ODmAf/gmftlLGMZy0E/4cF5GctYxnLCI1ydk7GMZSwnXPHaORnLWMYylrGMZSxjGctYxnLCI1zdfI5n7pexjGUsJ1zx2s1X+Bgv3SdjGctYTniOb73xDX50n4xlLGM54ZXzMpaxjOWEp/gOH7r5AU/xp/+XsYxlLCf9jg/cXN0vYxnLWE76BV84LmMZy1hOeok/8NgxGctYxnLSBZ84LmMZy1jGMpaxjGUsYxnLWMYylrGM/QcveSYtWVhfgwAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{N0f8}, adjoint(::Array{N0f8,2})) with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"First  image in train dataset is \", train_y[1])\n",
    "colorview(Gray, train_x[:,:,7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:60000\n",
    "    push!(X, reshape(train_x[:,:,i], 784))\n",
    "    y = zeros(10)\n",
    "    y[train_y[i] + 1] = 1.0\n",
    "    push!(Y, y)\n",
    "    end \n",
    "train_data = [x for x in zip(X,Y)]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:10000\n",
    "    push!(X, reshape(test_x[:,:,i], 784))\n",
    "    y = zeros(10)\n",
    "    y[test_y[i] + 1] = 1.0\n",
    "    push!(Y, y)\n",
    "    end \n",
    "test_data = [x for x in zip(X,Y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(N0f8[0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8  …  0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_network (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1.0/(1.0 + exp(-x))\n",
    "\n",
    "dσ(x) = σ(x) * (1 - σ(x))\n",
    "\n",
    "mutable struct neural_network\n",
    "    W\n",
    "    b\n",
    "end \n",
    "\n",
    "function create_network(input_layer_size, hidden_layer_size, output_layer_size)\n",
    "\n",
    "    W = [[0.0], randn(hidden_layer_size[1], input_layer_size)]\n",
    "    \n",
    "    b = [[0.0], randn(hidden_layer_size[1])]\n",
    "    \n",
    "    for i = 2:length(hidden_layer_size)\n",
    "        push!(W, randn(hidden_layer_size[i], hidden_layer_size[i-1]))\n",
    "        push!(b, randn(hidden_layer_size[i]))\n",
    "        end \n",
    "    push!(W, randn(output_layer_size, hidden_layer_size[end]))\n",
    "    push!(b, randn(output_layer_size))\n",
    "    \n",
    "    return neural_network(W,b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network(Array{Float64, N} where N[[0.0], [-2.1124934357008764 -0.6129709857566997 … 0.7822805025310664 0.034029284453676964; -0.10671027488164612 -0.39289503443053886 … -1.181874822434133 1.7905492577353828; … ; 0.7587807222942429 -1.0090615264792608 … -1.1868191520530553 -1.0314189402492537; -0.48449567411882605 0.2644332098155466 … 1.1966822080337407 0.585856097525903], [2.568128279544521 0.12090541033758566 … 0.05376754879537475 0.8510881759311291; -1.2791232460781805 1.178822502362354 … -0.9978497765900776 -0.1328889839677195; … ; -0.5521175819127995 1.6161734021257486 … -0.2740901945579535 -0.2103702231597336; 0.09016932791431778 0.5942913230819818 … 0.5221038831939038 -0.24661705412438148], [-0.03217159925314303 0.8353754421734642 … 2.360839384873267 -0.7981477719840981; 0.9054573663830546 0.551745209013391 … -0.9408512770302969 -1.9029637003099324; … ; 0.16817024062406705 -1.7295702900273948 … 0.21598688365169777 0.005355292612531826; -0.5882131382670795 0.8555775178320015 … -1.51080103812101 -1.2181885191261665], [-0.03689270089028026 -1.0472853710572279 … -0.7206845721279129 -0.4164311345799767; 0.33534383605300166 0.16211657150692804 … -0.23832154906644212 -0.5227229306515672; … ; 0.44314893393789717 0.7187981283733804 … 0.43797105853087864 -0.10345204270555294; -0.6001352939127985 -1.125312897704512 … 1.111275128493571 0.12782964180767914]], [[0.0], [-0.6401054919989543, 0.012535268152200294, 0.8506355333627718, -0.14154940410389133, 1.115343601224218, 0.5133167630699338, -0.48623422047165954, -0.6032302163070192, -1.007601741624368, -1.4805326908299206  …  0.7720790936852953, -0.6015971775500315, -0.461696553884073, -1.1460648243856046, -0.19151263606970526, 0.2768472779539132, -0.4863811849781901, 1.5059165598092263, 0.6322640085188624, -0.203840101271219], [-1.3716736997596228, 0.7664705316458765, -0.2330873573431806, 0.5586933514032297, 0.04557959132234482, -0.7783361595928865, 1.549758439108669, -0.4611466810039472, 0.06614506262722841, -0.45819262953573514  …  0.18128846567078966, 1.953516770396215, 0.6923451255992096, 1.6244085263955366, 0.9230682489901421, 0.3549415623241263, -0.6660378416448467, -0.2709581059611819, -0.2157447439536076, 0.6367752216952632], [-0.01766488217098672, -1.1919937598767723, -0.2567692396782781, 0.5839826168017619, -0.715065312027904, -0.8843406534796805, 0.700219133263529, -1.7907048374527963, 0.2469266133737619, 2.388883001618457  …  0.19636339017268117, 0.20758958677205352, 1.5562036269127255, -0.7250001017602675, -0.9166430438022402, 0.6595916491754245, 0.4708180000033177, -0.1668344997341716, 0.8540277048978224, -1.9468760504027596], [-1.3894218943194983, 0.483839007728756, 0.126682742745194, 1.5311293504605468, 0.2992257887419771, 0.5190634313287105, -0.9439914584249307, 1.310316626618764, -1.3767491398283067, 0.9135341989687198]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = create_network(784, [100,100,100], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(100, 784)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "for w in NN.W\n",
    "    print(size(w),\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for b in NN.b\n",
    "    print(size(b),\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward_pass(network, training_instance)\n",
    "    Z = [[0.0]]\n",
    "    \n",
    "    A = [training_instance[1]]\n",
    "    \n",
    "    for i = 2:length(network.W)\n",
    "        push!(Z, network.W[i] * A[i-1] + network.b[i])\n",
    "        push!(A, σ.(Z[i]))\n",
    "    end \n",
    "    return Z, A\n",
    "end\n",
    "\n",
    "function predict(network, training_instance)\n",
    "    Z,A = forward_pass(network, training_instance)\n",
    "    return argmax(A[end]) -1 \n",
    "end \n",
    "\n",
    "function success_percentage(network, data_set)\n",
    "    return sum([predict(network, x)== argmax(x[2]) - 1 ? 1 : 0 for x in data_set]) / length(data_set)*100\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error_deltas (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function error_deltas(network, training_instance)\n",
    "    L = size(network.W)[1]\n",
    "    Z , A =  forward_pass(network, training_instance)\n",
    "    δ = [(A[end] - training_instance[2]).* dσ.(Z[end])]\n",
    "    \n",
    "    for i = L-1:-1:2\n",
    "        pushfirst!(δ, (network.W[i+1]'*δ[1]).*dσ.(Z[i]))\n",
    "    end \n",
    "    \n",
    "    pushfirst!(δ, [0.0])\n",
    "    return A, δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test, δ_test = error_deltas(NN, train_data[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "  0.0\n",
       "  0.00039457280532357756\n",
       "  0.00023099447881043847\n",
       "  0.0\n",
       "  0.014738484126670476\n",
       " -0.00039063015478804034\n",
       "  0.11414692705604175\n",
       "  0.05317328965270868\n",
       "  8.995122554393016e-5\n",
       "  0.00011465891341097401"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δ_test[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mini_batch_update! (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_random_mini_batch(mini_batch_size, data_set)\n",
    "    k = rand(1:size(data_set)[1] - mini_batch_size)\n",
    "    return data_set[k:k+mini_batch_size]\n",
    "end \n",
    "\n",
    "function mini_batch_update!(network::neural_network, mini_batch_size::Int64, data_set, α::Float64)\n",
    "    batch = make_random_mini_batch(mini_batch_size, data_set)\n",
    "    \n",
    "    L = length(network.W)\n",
    "    \n",
    "    A, δ = error_deltas(network, batch[1])\n",
    "    A_batch = []\n",
    "    δ_batch = []\n",
    "    push!(A_batch, A)\n",
    "    push!(δ_batch, δ)\n",
    "    \n",
    "    for i = 2:mini_batch_size\n",
    "        A, δ = error_deltas(network, batch[i])\n",
    "        push!(A_batch, A)\n",
    "        push!(δ_batch, δ)\n",
    "        end \n",
    "    for l = L:-1:2\n",
    "        network.W[l] -= (α/ mini_batch_size)*sum([δ_batch[i][l]*A_batch[i][l-1]' for i = 1:mini_batch_size])\n",
    "        network.b[l] -= (α/ mini_batch_size)*sum([δ_batch[i][l] for i = 1:mini_batch_size])\n",
    "        end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 5000\n",
      "The percentage of correct classified images is:51.12\n",
      "\n",
      "Epochs 10000\n",
      "The percentage of correct classified images is:75.28\n",
      "\n",
      "Epochs 15000\n",
      "The percentage of correct classified images is:79.84\n",
      "\n",
      "Epochs 20000\n",
      "The percentage of correct classified images is:79.58\n",
      "\n",
      "Epochs 25000\n",
      "The percentage of correct classified images is:82.99\n",
      "\n",
      "Epochs 30000\n",
      "The percentage of correct classified images is:79.9\n",
      "\n",
      "Epochs 35000\n",
      "The percentage of correct classified images is:82.69\n",
      "\n",
      "Epochs 40000\n",
      "The percentage of correct classified images is:84.73\n",
      "\n",
      "Epochs 45000\n",
      "The percentage of correct classified images is:85.26\n",
      "\n",
      "Epochs 50000\n",
      "The percentage of correct classified images is:86.11\n",
      "\n",
      "Epochs 55000\n",
      "The percentage of correct classified images is:84.74000000000001\n",
      "\n",
      "Epochs 60000\n",
      "The percentage of correct classified images is:87.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i = 1:60000\n",
    "    mini_batch_update!(NN, 2, train_data, 0.4)\n",
    "    if i % 5000 == 0\n",
    "        println(\"Epochs \",i)\n",
    "        println(\"The percentage of correct classified images is:\",success_percentage(NN, test_data),\"\\n\")       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of Epochs increases, the percentage of classified images increases as well. In fact, with the previous run by 60000, the percentage increases from 51.12 to 87.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predict_image (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function show_test_img(i)\n",
    "    colorview(Gray, test_x[:,:,i])\n",
    "end\n",
    "\n",
    "function Predict_image(network::neural_network, i::Int64, testing_data)\n",
    "    println(\"Predicted number: \", predict(network, test_data[i]))\n",
    "    println(\"Actual Number: \", argmax(testing_data[i][2]) -1)\n",
    "    show_test_img(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number: 5\n",
      "Actual Number: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf1JREFUaAW9wT+IlgUAB+Dn4EcGeih0Yd4tgq5Hgi01BEIUNobR1qIYYQQNgYu2NlyLFIgFEQgNTQ4OjtEN1toiIeikIpeD0qAG1/AOx/H96RNefs8TZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWI/gAH+FD3MMGvsc/JkVZlEVZjGATqziIt/EN1vClSVEWZVEWL+BVfIxlXMVtg4f4Fj/hN6zjLaxgy25RFmVRFgvah6t4x2A/vrDbE/yJdRw2XZRFWZTFgm7hkB2ncAl3TLeMV7BltyiLsiiLBa1hG7/idazhO7xvt1Us4S/8bVKURVmUxYJu4hbO4BpOYj9ewwODFZzANn7ElklRFmVRFnO8hA3cx3t4bLCBk3gT1/E5buKiwSaumC7KoizKYo6zOGfwMr4y2MQVfIKjuIQ/cBbPcBrPTRdlURZlMccpO96w4198indxGMdwzOAH3DZblEVZlMUcq1gy+NmkI/ga6wZ38Jn5oizKoizm2Ma2wS+mO+/FRFmURVks6KlxRFmURVnMsIJlg8vGE2VRFmWxgC3jibIoi7KY4QD2Ygl7jCfKoizKYobj2IdHuGA8URZlURYz3DV4jOfGE2VRFmXxPzaMK8qiLMpijie4YVxRFmVRFjP8jgPGF2VRFmVRFmVRFmX/AfFVRNEl0kbhAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{N0f8}, ::Array{N0f8,2}) with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i  =  rand([x for x = 1:10000])\n",
    "Predict_image(NN, i, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
