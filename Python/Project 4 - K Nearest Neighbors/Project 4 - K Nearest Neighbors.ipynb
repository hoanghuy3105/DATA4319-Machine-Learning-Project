{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huy Huynh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA 4319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems. It’s easy to implement and understand, but has a major drawback of becoming significantly slows as the size of that data in use grows.\n",
    "\n",
    "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) in a feature space closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final1_ibdm8a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN works like ”Show me your friends, and I’ll tell you who you are.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The KNN Algorithm\n",
    "1. Load the data\n",
    "\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "\n",
    "3. For each example in the data\n",
    "\n",
    "    3.1 Calculate the distance between the query example and the current example from the data.\n",
    "\n",
    "    3.2 Add the distance and the index of the example to an ordered collection\n",
    "\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "\n",
    "5. Pick the first K entries from the sorted collection\n",
    "\n",
    "6. Get the labels of the selected K entries\n",
    "\n",
    "7. If regression, return the mean of the K labels\n",
    "\n",
    "8. If classification, return the mode of the K labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the right value for K\n",
    "To select the K that’s right for your data, we run the KNN algorithm several times with different values of K and choose the K that reduces the number of errors we encounter while maintaining the algorithm’s ability to accurately make predictions when it’s given data it hasn’t seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, query, k, distance_fn, choice_fn):\n",
    "    neighbor_distances_and_indices = []\n",
    "    \n",
    "    # 3. For each example in the data\n",
    "    for index, example in enumerate(data):\n",
    "        # 3.1 Calculate the distance between the query example and the current\n",
    "        # example from the data.\n",
    "        distance = distance_fn(example[:-1], query)\n",
    "        \n",
    "        # 3.2 Add the distance and the index of the example to an ordered collection\n",
    "        neighbor_distances_and_indices.append((distance, index))\n",
    "    \n",
    "    # 4. Sort the ordered collection of distances and indices from\n",
    "    # smallest to largest (in ascending order) by the distances\n",
    "    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n",
    "    \n",
    "    # 5. Pick the first K entries from the sorted collection\n",
    "    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n",
    "    \n",
    "    # 6. Get the labels of the selected K entries\n",
    "    k_nearest_labels = [data[i][-1] for distance, i in k_nearest_distances_and_indices]\n",
    "\n",
    "    # 7. If regression (choice_fn = mean), return the average of the K labels\n",
    "    # 8. If classification (choice_fn = mode), return the mode of the K labels\n",
    "    return k_nearest_distances_and_indices , choice_fn(k_nearest_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(labels):\n",
    "    return sum(labels) / len(labels)\n",
    "\n",
    "def mode(labels):\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    sum_squared_distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        sum_squared_distance += math.pow(point1[i] - point2[i], 2)\n",
    "    return math.sqrt(sum_squared_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    # Regression Data\n",
    "    # \n",
    "    # Column 0: height (inches)\n",
    "    # Column 1: weight (pounds)\n",
    "    '''\n",
    "    reg_data = [\n",
    "       [65.75, 112.99],\n",
    "       [71.52, 136.49],\n",
    "       [69.40, 153.03],\n",
    "       [68.22, 142.34],\n",
    "       [67.79, 144.30],\n",
    "       [68.70, 123.30],\n",
    "       [69.80, 141.49],\n",
    "       [70.01, 136.46],\n",
    "       [67.90, 112.37],\n",
    "       [66.49, 127.45],\n",
    "    ]\n",
    "    \n",
    "    # Question:\n",
    "    # Given the data we have, what's the best-guess at someone's weight if they are 60 inches tall?\n",
    "    reg_query = [60]\n",
    "    reg_k_nearest_neighbors, reg_prediction = knn(\n",
    "        reg_data, reg_query, k=3, distance_fn=euclidean_distance, choice_fn=mean\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    # Classification Data\n",
    "    # \n",
    "    # Column 0: age\n",
    "    # Column 1: likes pineapple\n",
    "    '''\n",
    "    clf_data = [\n",
    "       [22, 1],\n",
    "       [23, 1],\n",
    "       [21, 1],\n",
    "       [18, 1],\n",
    "       [19, 1],\n",
    "       [25, 0],\n",
    "       [27, 0],\n",
    "       [29, 0],\n",
    "       [31, 0],\n",
    "       [45, 0],\n",
    "    ]\n",
    "    # Question:\n",
    "    # Given the data we have, does a 33 year old like pineapples on their pizza?\n",
    "    clf_query = [33]\n",
    "    clf_k_nearest_neighbors, clf_prediction = knn(\n",
    "        clf_data, clf_query, k=3, distance_fn=euclidean_distance, choice_fn=mode\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "The algorithm is simple and easy to implement.\n",
    "There’s no need to build a model, tune several parameters, or make additional assumptions. The algorithm is versatile. It can be used for classification, regression, and search.\n",
    "\n",
    "### Disadvantages\n",
    "The algorithm gets significantly slower as the number of examples and/or predictors/independent variables increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine for a moment. We are navigating the Netflix and we encounter The Post. We are not sure that we want to watch it, but its genres intrigue us; we are curious about other similar movies. We scroll down to the “Similar to this movie” section to see what recommendations Netflix will make, and the algorithmic gears begin to turn.\n",
    "\n",
    "Netflix sends a request to its back-end for the 5 movies that are most similar to The Post. The back-end has a recommendation data set exactly like ours. It begins by creating the row representation (better known as a feature vector) for The Post, then it runs a program similar to the one below to search for the 5 movies that are most similar to The Post, and finally sends the results back to the Netflix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](https://assets.nflxext.com/ffe/siteui/allow-robots/contentSampling/seo-watch-free-link-preview.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Years a Slave\n",
      "Hacksaw Ridge\n",
      "Queen of Katwe\n",
      "The Wind Rises\n",
      "A Beautiful Mind\n"
     ]
    }
   ],
   "source": [
    "from knn_from_scratch import knn, euclidean_distance\n",
    "\n",
    "def recommend_movies(movie_query, k_recommendations):\n",
    "    raw_movies_data = []\n",
    "    with open('movies_recommendation_data.csv', 'r') as md:\n",
    "        # Discard the first line (headings)\n",
    "        next(md)\n",
    "\n",
    "        # Read the data into memory\n",
    "        for line in md.readlines():\n",
    "            data_row = line.strip().split(',')\n",
    "            raw_movies_data.append(data_row)\n",
    "\n",
    "    # Prepare the data for use in the knn algorithm by picking\n",
    "    # the relevant columns and converting the numeric columns\n",
    "    # to numbers since they were read in as strings\n",
    "    movies_recommendation_data = []\n",
    "    for row in raw_movies_data:\n",
    "        data_row = list(map(float, row[2:]))\n",
    "        movies_recommendation_data.append(data_row)\n",
    "\n",
    "    # Use the KNN algorithm to get the 5 movies that are most\n",
    "    # similar to The Post.\n",
    "    recommendation_indices, _ = knn(\n",
    "        movies_recommendation_data, movie_query, k=k_recommendations,\n",
    "        distance_fn=euclidean_distance, choice_fn=lambda x: None\n",
    "    )\n",
    "\n",
    "    movie_recommendations = []\n",
    "    for _, index in recommendation_indices:\n",
    "        movie_recommendations.append(raw_movies_data[index])\n",
    "\n",
    "    return movie_recommendations\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    the_post = [7.2, 1, 1, 0, 0, 0, 0, 1, 0] # feature vector for The Post\n",
    "    recommended_movies = recommend_movies(movie_query=the_post, k_recommendations=5)\n",
    "\n",
    "    # Print recommended movie titles\n",
    "    for recommendation in recommended_movies:\n",
    "        print(recommendation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Netflix recommends 12 Years A Slave, Hacksaw Ridge, Queen of Katwe, The Wind Rises, and A Beautiful Mind. Those are 5 movies similar to The Post and we fully understand how the KNN algorithm works by telling similar vectors based on the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
